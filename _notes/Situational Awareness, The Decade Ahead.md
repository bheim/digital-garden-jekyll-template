AI is growing in capabilities very fast from preschooler to elementary schooler to smart high schoolers and the question is how far it will go
- *When it comes to ASI though, the question for me is less if it can achieve AGI but how it gets beyond that asymptote; with effective collaboration though, we basically have an infinite number of humans working problems (since we can make energy-efficient AI systems)*
Trends right now: exponentially more compute being used, exponentially more efficient usage of that compute
- epochAI estimating .5 OOMs/year of algorithmic efficiency
Because we're running out of textual data, priorities are shifting to identifying strategies to find other training methods (such as synehtic data, self-play, and reinforcement learning)

The textbook analogy:
When humans read a textbook well, they read it slowly, digest the material, make connections to other things they know, and make predictions. Current training doesn't do that. It just "reads it" and encodes it in gradient descent without any reflection. What will it look like when it begins to reflect?
- Or imagine if we just limit the data to be more from experts and their reasoning and less from the average Joe?

Algorithmic improvements
- RLHF
- Chain of Thought
- Scaffolding
	- One model creates the plan, another model proposes solutions, another critiques them, and you can build this out as much as you'd like
Models don't have long-term memory, often don't think before speaking; imagine what an agent could do after several months of listening into zoom calls, watching you work and listening to your reasoning

With all of these advancements, the author expects 3-6 OOMs increase from 2023 to 2027

#### From AGI to SuperIntelligence
Notion of achieving AGI -> millions of AGIs compress progress into short timespan
AGI compressing AI research by 10 years is a conservative estimate (we have thousands? of capability researchers right now and would have access to millions)
- AGI doesn't need to do everything; it just needs to do AI researche
Potential bottlenecks
- compute
- remaining pieces of research that requires humans -> big bottleneck
- algorithms may hit diminishing returns and OOMs won't come anymore
- low hanging fruit gone so increased compute and AI will simply maintian pace
	- he sees that in the past, we don't see such exponential need for effort to continue rapid pace of discovery so AI growth will outpace difficulty of problems

#### The Challenges
Compute and energy are biggest limiters

#### Security for AGI
I'm not reading this because I'm going to read other articles on this topic

#### Superalignment
Technical problem that our current solutions can't scale up to solve
It's easier to check than create (this is very beneficial); AIs can help us check and let humans also have a say
We can learn about what AI does on easy problems to try to generalize how it will approach the hard ones and use similar strategies

[[mechanistic interpretability]] may be very helpful here, especially when using top-down strategies -> finding neurons that light up, for example, when being helpful and honest versus harmful and deceitful

The best route for alignment is getting early AGIs to work on safety. We need strong monitoring systems, have targeted capability limitations, 

#### The Free World Must Prevail
China has been behind on chips, LLMs, and research but they can build quickly without the same permits and environmental laws as the US. Power generation is a key bottleneck and China easily outpaces the US in developing it.

On top of this, the whole "what if they steal weights" thing doesn't matter much att the moment, but it matters a whole lot once you have AGI and AGI is the driver of research

#### The Project
The USG will get involved in this and it will not be up to a private company to determine our path


